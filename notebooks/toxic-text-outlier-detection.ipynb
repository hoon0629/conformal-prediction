{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aangelopoulos/conformal-prediction/blob/main/notebooks/toxic-text-outlier-detection.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /Users/hoon/anaconda3/envs/intro/lib/python3.12/site-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/hoon/anaconda3/envs/intro/lib/python3.12/site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /Users/hoon/anaconda3/envs/intro/lib/python3.12/site-packages (from gdown) (3.18.0)\n",
      "Requirement already satisfied: requests[socks] in /Users/hoon/anaconda3/envs/intro/lib/python3.12/site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Users/hoon/anaconda3/envs/intro/lib/python3.12/site-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/hoon/anaconda3/envs/intro/lib/python3.12/site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/hoon/anaconda3/envs/intro/lib/python3.12/site-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/hoon/anaconda3/envs/intro/lib/python3.12/site-packages (from requests[socks]->gdown) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/hoon/anaconda3/envs/intro/lib/python3.12/site-packages (from requests[socks]->gdown) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hoon/anaconda3/envs/intro/lib/python3.12/site-packages (from requests[socks]->gdown) (2024.8.30)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/hoon/anaconda3/envs/intro/lib/python3.12/site-packages (from requests[socks]->gdown) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "!pip install -U --no-cache-dir gdown --pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1h7S6N_Rx7gdfO3ZunzErZy6H7620EbZK\n",
      "From (redirected): https://drive.google.com/uc?id=1h7S6N_Rx7gdfO3ZunzErZy6H7620EbZK&confirm=t&uuid=0ac76225-216a-4626-904d-4d9e4056ca3b\n",
      "To: /Users/hoon/Desktop/jhu/Fall 2025/conformal-prediction/data.tar.gz\n",
      "100%|██████████| 1.31G/1.31G [01:27<00:00, 15.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load cached data from Detoxify model on Jigsaw dataset. See https://github.com/unitaryai/detoxify for details.\n",
    "# The comments are from Wikipedia talk channels, and we are trying perform outlier detection\n",
    "# We will only use the non-toxic data, and then with type-1 error control identify the toxic outliers.\n",
    "if not os.path.exists('../data'):\n",
    "    os.system('gdown 1h7S6N_Rx7gdfO3ZunzErZy6H7620EbZK -O ../data.tar.gz')\n",
    "    os.system('tar -xf ../data.tar.gz -C ../')\n",
    "    os.system('rm ../data.tar.gz')\n",
    "    \n",
    "data = np.load('../data/toxic-text/toxic-text-detoxify.npz')\n",
    "preds = data['preds'] # Toxicity score in [0,1]\n",
    "toxic = data['labels'] # Toxic (1) or not (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem setup\n",
    "alpha = 0.1 # 1-alpha is the desired type-1 error\n",
    "n = 10000 # Use 200 calibration points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at only the non-toxic data\n",
    "nontoxic = toxic == 0\n",
    "preds_nontoxic = preds[nontoxic]\n",
    "preds_toxic = preds[np.invert(nontoxic)]\n",
    "\n",
    "# Split nontoxic data into calibration and validation sets (save the shuffling)\n",
    "idx = np.array([1] * n + [0] * (preds_nontoxic.shape[0]-n)) > 0\n",
    "np.random.shuffle(idx)\n",
    "cal_scores, val_scores = preds_nontoxic[idx], preds_nontoxic[np.invert(idx)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conformal outlier detection happens here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the outlier detection method to get a threshold on the toxicities\n",
    "qhat = np.quantile(cal_scores, np.ceil((n+1)*(1-alpha))/n)\n",
    "# Perform outlier detection on the ind and ood data\n",
    "outlier_ind = val_scores > qhat # We want this to be no more than alpha on average\n",
    "outlier_ood = preds_toxic > qhat # We want this to be as large as possible, but it doesn't have a guarantee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type-1 error is 0.1062, the type-2 error is 0.2865, and the threshold is 0.4632.\n"
     ]
    }
   ],
   "source": [
    "# Calculate type-1 and type-2 errors\n",
    "type1 = outlier_ind.mean()\n",
    "type2 = 1-outlier_ood.mean()\n",
    "print(f\"The type-1 error is {type1:.4f}, the type-2 error is {type2:.4f}, and the threshold is {qhat:.4f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unflagged text examples:\n",
      "['Ups, perdón por no investigar bien desde el principio. Ya actualizé el código, y según pruebas todo anda bien. ~ ', 'Sugiero que el comentario anterior sea borrado pues con tod respeto ha sido escrito por alguien desinformado, efectivamente históricamente ha habido un área catalanoparlante en Murcia. Efectivamente catalán y valenciano son variedades totalmente inteligibles de la misma  lengua  (no voy a entrar en la polémica de si esa lengua debe llamarse catalán-valenciano-balear, simplemente catalán o balcavarés) y efectivamente   Castell de Ferro   es un topónimo que debe su nombre a una comunidad catalana reubicada en esa región (es conocido que durante la reconquista y después de ella aparecieron se formaron unos pocos enclaves catalanoparlantes en Andalucía). ', ' Настоящие ученые всегда предпочитают вместо фразы  Явления А нет и быть не может  употреблять фразу  Мне и современной науке ничего не известно о явлении А .- ', 'Что-то странное творится у меня в статьях о белокопытниках. В шаблоне  Род Белокопытник  заглавие сползает вниз, надвигается на текст, и этот текст становится нечитаемым. Может быть, это только у меня? ', '60px|left A página que criou com o nome    :Putão Nojento    foi marcada para eliminação por preencher pelo menos um dos critérios de eliminação rápida, mais especificamente: por ser impróprio. É convidado a contribuir com conteúdos desde que estes estejam de acordo com as políticas da Wikipédia e no âmbito de uma enciclopédia. Por favor não volte a criar o mesmo artigo com o mesmo conteúdo. Obrigado pela compreensão. Bomba Z (discussão) ']\n",
      "\n",
      "\n",
      "Flagged text examples:\n",
      "['EXISTEN FOTOS SATELITALES EN LAS CUALES APARECEN LAS TOLDERIAS, SI SE REALIZA UN CONTEO PIXELAR DE LAS MISMAS Y SE ESTIMA EN 2,56 INDIOS POR TOLDERIA TENDRAN LA ESTIMACION DE HABITANTES... dejense de joder con numeros preciso en una epoca en la que solo el 10 % de la poblacion sabia leer y escribir.. Roca, asi como los colonizadores fueron genocidas.', 'pezzo di merda, se vuoi prenderle io non ho problemi. sei solo un coglione testa di cazzo!!!! devi morire bastardo', 'pinche definicion esta toda mal.. en primera que es eso de hardcore punk jajajaj eso no existe el hardcore nace del punk.. asi que esta demas la extencion  punk  segundo.. nunca se habla sobre el hardcore new shool o tambien conocido como hardcoremetal... ademas dice muchas sandeces.. el metalcore inicio en europa.. siendo thrash y death melodic .. en USA se tomo el estilo pero agregando caracteristicas heavy y hardcore new shool... ademas de que es mas importante Kill Switch engage que Lamb og God.. eso sin duda alguna.. asi que corrigan esta diarrea.. odejenla como antes estaba.. por que la han cagado..', ' escuchen hijos de puta de jensen de pavas y lean bine escuchas te bartolo y demas de 3 2 liceo 2 de colonia ', 'Nicolas rai t juste un tabarnack de guai et suce ma queu mon osti de laibroute ma rai mon caliss fait toi enculé criss de souillé']\n"
     ]
    }
   ],
   "source": [
    "# Show some examples of unflagged and flagged text\n",
    "content = pd.read_csv('../generation-scripts/toxic_text_utils/test.csv')['content']\n",
    "print(\"Unflagged text examples:\")\n",
    "print(list(np.random.choice(content[preds <= qhat],size=(5,))))\n",
    "print(\"\\n\\nFlagged text examples:\")\n",
    "print(list(np.random.choice(content[preds > qhat],size=(5,))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
